{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b64632-29db-4bf1-bded-8a417a922cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ[\"RAY_DISABLE_WINDOWS_CRASH_HANDLER\"] = \"1\"\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 224 → 112\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 112 → 56\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb08300a-f118-47f9-b09f-21c1b60cf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "def load_datasets(data_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "    num_classes = len(full_dataset.classes)\n",
    "\n",
    "    indices = np.random.permutation(len(full_dataset))\n",
    "    splits = np.array_split(indices, 3)\n",
    "\n",
    "    client_datasets = []\n",
    "    for split in splits:\n",
    "        train_idx = split[:int(0.8 * len(split))]\n",
    "        test_idx  = split[int(0.8 * len(split)):]\n",
    "        client_datasets.append((\n",
    "            Subset(full_dataset, train_idx),\n",
    "            Subset(full_dataset, test_idx)\n",
    "        ))\n",
    "\n",
    "    return client_datasets, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e2a983-2a73-4cff-8194-b07bae0ab8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, device, epochs=1):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee338a6-2bd4-4f4b-882f-1d2226c88cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import csv\n",
    "from flwr.common import parameters_to_ndarrays\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainset, testset, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "        self.testloader  = DataLoader(testset, batch_size=32)\n",
    "\n",
    "    def get_parameters(self, config=None):\n",
    "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config=None):\n",
    "        self.set_parameters(parameters)\n",
    "        train(self.model, self.trainloader, self.device, epochs=1)\n",
    "        return self.get_parameters(), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config=None):\n",
    "        self.set_parameters(parameters)\n",
    "        acc = test(self.model, self.testloader, self.device)\n",
    "        return float(1 - acc), len(self.testloader.dataset), {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c429c9-7560-445a-b47d-a0c9b0a6f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "def client_fn(context: Context):\n",
    "    cid = int(context.node_config[\"partition-id\"])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleCNN(NUM_CLASSES).to(device)\n",
    "\n",
    "    trainset, testset = CLIENT_DATASETS[cid]\n",
    "\n",
    "    client = FlowerClient(\n",
    "        model=model,\n",
    "        trainset=trainset,\n",
    "        testset=testset,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    return client.to_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18d0c0d-4284-4723-b1e1-9622f3355ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FedAvgWithLossLogging(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, model, num_rounds):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_rounds = num_rounds\n",
    "        self.history = []\n",
    "\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        aggregated_params, _ = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        if aggregated_params is None:\n",
    "            return None, {}\n",
    "\n",
    "        params = parameters_to_ndarrays(aggregated_params)\n",
    "        state_dict = dict(zip(self.model.state_dict().keys(), params))\n",
    "        self.model.load_state_dict(\n",
    "            {k: torch.tensor(v) for k, v in state_dict.items()},\n",
    "            strict=True,\n",
    "        )\n",
    "\n",
    "        return aggregated_params, {}\n",
    "\n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        aggregated_loss, _ = super().aggregate_evaluate(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_loss is None:\n",
    "            return None, {}\n",
    "\n",
    "        self.history.append({\n",
    "            \"round\": server_round,\n",
    "            \"global_loss\": aggregated_loss,\n",
    "            \"num_clients\": len(results),\n",
    "        })\n",
    "\n",
    "        print(\n",
    "            f\"[Server] Round {server_round} | Global Loss: {aggregated_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if server_round == self.num_rounds:\n",
    "            torch.save(\n",
    "                self.model.state_dict(),\n",
    "                \"models/global_model_final.pth\"\n",
    "            )\n",
    "            self._save_metrics()\n",
    "\n",
    "        return aggregated_loss, {}\n",
    "\n",
    "    def _save_metrics(self):\n",
    "        with open(\"metrics/training_metrics.csv\", \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(\n",
    "                f,\n",
    "                fieldnames=[\"round\", \"global_loss\", \"num_clients\"]\n",
    "            )\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.history)\n",
    "\n",
    "        print(\"[Server] Metrics saved to metrics/training_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508ddd31-8969-4ae5-a8ce-eb27137ec8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=7, no round_timeout\n",
      "2026-02-01 14:46:35,810\tINFO worker.py:2012 -- Started a local Ray instance.\n",
      "/home/dmlab/miniconda3/envs/multiomics/lib/python3.11/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 76750062796.0, 'node:10.132.197.241': 1.0, 'GPU': 1.0, 'memory': 179083479860.0, 'CPU': 128.0, 'accelerator_type:RTX': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 128 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(pid=gcs_server)\u001b[0m [2026-02-01 14:47:02,028 E 34881 34881] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[33m(raylet)\u001b[0m [2026-02-01 14:47:05,575 E 35135 35135] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(ClientAppActor pid=35276)\u001b[0m [2026-02-01 14:47:08,585 E 35276 35531] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2026-02-01 14:47:09,819 E 33103 35272] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 1 | Global Loss: 0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 2 | Global Loss: 0.1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 3 | Global Loss: 0.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 4 | Global Loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 5 | Global Loss: 0.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 6 | Global Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Round 7 | Global Loss: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 7 round(s) in 11342.11s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.7423363711681856\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.18521587038571297\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.13688667955445086\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.13145539906103285\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.10807327625886035\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.09702660406885759\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.10503544140660959\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Metrics saved to metrics/training_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.7423363711681856\n",
       "\tround 2: 0.18521587038571297\n",
       "\tround 3: 0.13688667955445086\n",
       "\tround 4: 0.13145539906103285\n",
       "\tround 5: 0.10807327625886035\n",
       "\tround 6: 0.09702660406885759\n",
       "\tround 7: 0.10503544140660959"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"plantvillage/color\"\n",
    "\n",
    "CLIENT_DATASETS, NUM_CLASSES = load_datasets(DATA_DIR)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GLOBAL_MODEL = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "strategy = FedAvgWithLossLogging(\n",
    "    model=GLOBAL_MODEL,\n",
    "    num_rounds=7\n",
    ")\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=3,\n",
    "    config=fl.server.ServerConfig(num_rounds=7),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86d4ea-d9b2-4584-aafe-f1158c6eb05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ef770-34f0-4a60-b0dd-c33bb2827c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
